if (abs(s)>=0.75) {combine[,nums][i][,1] = log(combine[,nums][i][,1]+1)}
i=i+1
}
skewness(combine$SalePrice)
#Where are the NAs?
nas = data.frame(sapply(combine, function(x) sum(is.na(x))))
nas$Names = rownames(nas)
nas = data.frame(nas[nas$sapply.combine..function.x..sum.is.na.x... != 0,])
nas = nas[order(-nas$sapply.combine..function.x..sum.is.na.x...),] #Get them in order of scale
nas
combine$Alley = NULL
combine$MiscFeature = NULL
combine$PoolQC = NULL
combine$Fence = NULL
combine$FireplaceQu = NULL
nas = data.frame(sapply(combine, function(x) sum(is.na(x))))
nas$Names = rownames(nas)
nas = data.frame(nas[nas$sapply.combine..function.x..sum.is.na.x... != 0,])
nas = nas[order(-nas$sapply.combine..function.x..sum.is.na.x...),] #Get them in order of scale
nas
i=1
while (i<=length(nas$Names)) {
temp = nas$Names[i]
temp_data = combine[!is.na(combine[,temp]),]
if (is.factor(combine[,nas$Names[i]])) {
temp_fit = rpart(temp_data[,temp] ~ ., method = 'class', data = temp_data)
combine[,temp][is.na(combine[,temp])] <- predict(temp_fit, combine[is.na(combine[,temp]),], type = 'class')
} else {
temp_fit = rpart(temp_data[,temp] ~ ., method = 'anova', data = temp_data)
combine[,temp][is.na(combine[,temp])] <- predict(temp_fit, combine[is.na(combine[,temp]),])
}
i=i+1
}
install.packages("glmnet")
library("glmnet")
sapply(combine, function(x) sum(is.na(x)))
write.csv(combine, "combined_no_na.csv")
combine$YearBuilt != combine$YearRemodAdd
combine$Remod = 0
combine$Remod[combine$YearBuilt != combine$YearRemodAdd] = 1
combine$Remod
combine$Remod = as.factor(combine$Remod)
combine$New1 = combine$TotalBsmtSF * combine$BsmtFinSF1
combine$New2 = combine$GarageCars * combine$GarageArea
combine$New3 = combine$GarageCars * combine$GarageYrBlt
combine$Remod = 0
combine$Remod[combine$YearBuilt != combine$YearRemodAdd] = 1
combine$Remod = as.factor(combine$Remod)
combine$AgeSold = combine$YrSold - combine$YearBuilt
combine$DateSold = paste(as.character(combine$MoSold), as.character(combine$YrSold), sep = '-')
combine$DateSold = as.yearmon(combine$DateSold, "%m-%Y")
combine$New4 = combine$1stflr + combine$2ndflr + combine$lowqualsf + combine$GrLivArea
combine$New4 = combine$X1stFlrSF + combine$X2ndFlrSF + combine$LowQualFinSF + combine$GrLivArea
combine$Total_sqf = combine$X1stFlrSF + combine$X2ndFlrSF + combine$LowQualFinSF + combine$GrLivArea
combine$Total_baths = combine$BsmtFullBath + combine$BsmtHalfBath + combine$FullBath + combine$HalfBath
combine = read.csv("combined_no_na.csv")
combine$X = NULL
combine$3SsnPorch
combine = read.csv("combined_no_na.csv")
combine$X = NULL
combine$New1 = combine$TotalBsmtSF * combine$BsmtFinSF1
combine$New2 = combine$GarageCars * combine$GarageArea
combine$New3 = combine$GarageCars * combine$GarageYrBlt
combine$Remod = 0
combine$Remod[combine$YearBuilt != combine$YearRemodAdd] = 1
combine$Remod = as.factor(combine$Remod)
combine$AgeSold = combine$YrSold - combine$YearBuilt
combine$DateSold = paste(as.character(combine$MoSold), as.character(combine$YrSold), sep = '-')
combine$DateSold = as.yearmon(combine$DateSold, "%m-%Y")
combine$Total_sqf = combine$X1stFlrSF + combine$X2ndFlrSF + combine$LowQualFinSF + combine$GrLivArea
combine$Total_baths = combine$BsmtFullBath + combine$BsmtHalfBath + combine$FullBath + combine$HalfBath
combine$Total_outside = combine$WoodDeckSF + combine$OpenPorchSF + combine$EnclosedPorch + combine$X3SsnPorch + combine$ScreenPorch
combine$X1stFlrSF = NULL
combine$X2ndFlrSF = NULL
combine$LowQualFinSF = NULL
combine$GrLivArea = NULL
combine$BsmtFullBath = NULL
combine$BsmtHalfBath = NULL
combine$FullBath = NULL
combine$HalfBath = NULL
combine$WoodDeckSF = NULL
combine$OpenPorchSF = NULL
combine$EnclosedPorch = NULL
combine$X3SsnPorch = NULL
combine$ScreenPorch = NULL
combine$BsmtFinSF1 = NULL
combine$BsmtFinSF2 = NULL
combine$BsmtUnfSF = NULL
combine[,-59]
head(combine[,59])
combine_p <- preProcess(combine[,-59], method = c("center", "scale"))
combine_t <- predict(combine_p, newdata = combine[,-59])
combine_t = cbind(combine_t, combine$SalePrice)
combine_t$Id = seq(1,2919,1)
combine = combine_t
colnames(combine)[68] = 'SalePrice'
write.csv(combine, "combined_preprocessed.csv")
train = combine[1:1460,]
test = combine[1461:2919,]
?Boruta
set.seed(1)
bor.results <- Boruta(train, train$SalePrice, maxRuns=20, doTrace=0)
att = getSelectedAttributes(bor.results, withTentative = T)
att
bor.results
plot(bor.results)
train_bor = train[att]
test_bor = test[att]
write.csv(train_bor, "train_bor.csv")
write.csv(test_bor, "test_bor.csv")
colnames(train_bor)[1]
View(train_bor)
train_bor = read.csv("train_bor.csv")
test_bor = read.csv("test_bor.csv")
colnames(train_bor)[1] = 'Id'
colnames(test_bor)[1] = 'Id'
train_bor$Remod = as.factor(train_bor$Remod)
test_bor$Remod = as.factor(test_bor$Remod)
plot(train$SalePrice, train$YrSold)
plot(train$YrSold, train$SalePrice)
train_date = read.csv("train_date.csv")
test_date = read.csv("test_date.csv")
plot(train_date, train$SalePrice)
train_date
plot(train_date$x, train$SalePrice)
plot(train_date$x, exp(train$SalePrice))
set.seed(1)
fitControl <- trainControl(method = "repeatedcv", number = 5, repeats = 5, verboseIter=FALSE,
classProbs=FALSE)
model = train(SalePrice ~.,
data = train_bor,
method = 'glmnet',
trControl = fitControl,
#preProcess=c("pca"),
metric = "RMSE")
model
library('caretEnsemble')
model_list <- caretList(SalePrice ~. -Id,
data=train_bor,
trControl=fitControl,
tuneList = list(
glmnet=caretModelSpec(method = 'glmnet'),
gbm=caretModelSpec(method = 'gbm'),
rf=caretModelSpec(method = 'rf'),
xgbTree=caretModelSpec(method = 'xgbTree')),
metric = 'RSME')
model_list
getTrainPerf(model_list$rf)
getTrainPerf(model_list$gbm)
getTrainPerf(model_list$xgb)
getTrainPerf(model_list$glmnet)
caret_list_data = save(model_list, file = 'caret_list_data.RData')
gbm_ensemble <- caretStack(
model_list,
method="gbm",
metric="RSME",
trControl=trainControl(
method="boot",
number=10,
savePredictions="final"
)
)
gbm_ensemble
gbm_ensemble$models
summary(gbm_ensemble)
ens_preds <- predict(gbm_ensemble, newdata=test_bor)
ens_preds = exp(ens_preds)
ens_preds
sample = read.csv('sample_submission.csv')
sub = data.frame(test_bor$Id, ens_preds)
colnames(sub) = c("Id", "SalePrice")
write.csv(sub, "sub_041116b.csv")
# Load libraries and data -------------------------------------------------
library('caret')
library('Boruta')
library('zoo')
library('e1071')
library('rpart')
library("glmnet")
train = read.csv("train.csv", stringsAsFactors = T)
test = read.csv("test.csv", stringsAsFactors = T)
# Simple pre-processing ---------------------------------------------------
#log transform the target,
train$SalePrice = log(train$SalePrice)
test$SalePrice = 0
sp = c(train$SalePrice, test$SalePrice) #Keep the saleprice data
combine = rbind(train, test) #Combine
combine$Id = NULL
#x1 = combine$YearRemodAdd
#x2 = combine$YearBuilt
#x3 = combine$MoSold
#x4 = combine$YrSold
nums <- sapply(combine, is.numeric)
i=1
while (i<length(nums[nums=='TRUE'])) {
s = skewness(combine[,nums][i][,1], na.rm = T)
if (abs(s)>=0.75) {combine[,nums][i][,1] = log(combine[,nums][i][,1]+1)}
i=i+1
}
#combine[,nums] = log(combine[,nums]+1) #Log tranform the numeric variables
#combine$SalePrice = sp #Put the right saleprices back
#combine$YearRemodAdd = x1
#combine$YearBuilt = x2
#combine$MoSold = x3
#combine$YrSold = x4
#KAGGLE HOUSE PRICE PREDICTIONS
#Today...
# Load libraries and data -------------------------------------------------
library('caret')
library('Boruta')
library('zoo')
library('e1071')
library('rpart')
library("glmnet")
train = read.csv("train.csv", stringsAsFactors = T)
test = read.csv("test.csv", stringsAsFactors = T)
# Simple pre-processing ---------------------------------------------------
#log transform the target,
train$SalePrice = log(train$SalePrice)
test$SalePrice = 0
sp = c(train$SalePrice, test$SalePrice) #Keep the saleprice data
combine = rbind(train, test) #Combine
combine$Id = NULL
#x1 = combine$YearRemodAdd
#x2 = combine$YearBuilt
#x3 = combine$MoSold
#x4 = combine$YrSold
nums <- sapply(combine, is.numeric)
i=1
while (i<length(nums[nums=='TRUE'])) {
s = skewness(combine[,nums][i][,1], na.rm = T)
if (abs(s)>=0.75) {combine[,nums][i][,1] = log(combine[,nums][i][,1]+1)}
i=i+1
}
#combine[,nums] = log(combine[,nums]+1) #Log tranform the numeric variables
#combine$SalePrice = sp #Put the right saleprices back
#combine$YearRemodAdd = x1
#combine$YearBuilt = x2
#combine$MoSold = x3
#combine$YrSold = x4
# Tidy the data -----------------------------------------------------------------
#Where are the NAs?
nas = data.frame(sapply(combine, function(x) sum(is.na(x))))
nas$Names = rownames(nas)
nas = data.frame(nas[nas$sapply.combine..function.x..sum.is.na.x... != 0,])
nas = nas[order(-nas$sapply.combine..function.x..sum.is.na.x...),] #Get them in order of scale
#Majority is NAs. Get rid of them...
combine$Alley = NULL
combine$MiscFeature = NULL
combine$PoolQC = NULL
combine$Fence = NULL
combine$FireplaceQu = NULL
i=1
while (i<=length(nas$Names)) {
temp = nas$Names[i]
temp_data = combine[!is.na(combine[,temp]),]
if (is.factor(combine[,nas$Names[i]])) {
temp_fit = rpart(temp_data[,temp] ~ ., method = 'class', data = temp_data)
combine[,temp][is.na(combine[,temp])] <- predict(temp_fit, combine[is.na(combine[,temp]),], type = 'class')
} else {
combine[,temp] = mean(combine[,temp], na.rm = T)
}
i=i+1
}
temp
combine[,temp]
#Where are the NAs?
nas = data.frame(sapply(combine, function(x) sum(is.na(x))))
nas$Names = rownames(nas)
nas = data.frame(nas[nas$sapply.combine..function.x..sum.is.na.x... != 0,])
nas = nas[order(-nas$sapply.combine..function.x..sum.is.na.x...),] #Get them in order of scale
i=1
while (i<=length(nas$Names)) {
temp = nas$Names[i]
temp_data = combine[!is.na(combine[,temp]),]
if (is.factor(combine[,nas$Names[i]])) {
temp_fit = rpart(temp_data[,temp] ~ ., method = 'class', data = temp_data)
combine[,temp][is.na(combine[,temp])] <- predict(temp_fit, combine[is.na(combine[,temp]),], type = 'class')
} else {
combine[,temp] = mean(combine[,temp], na.rm = T)
}
i=i+1
}
combine[,temp]
nas = data.frame(sapply(combine, function(x) sum(is.na(x))))
nas$Names = rownames(nas)
nas = data.frame(nas[nas$sapply.combine..function.x..sum.is.na.x... != 0,])
nas = nas[order(-nas$sapply.combine..function.x..sum.is.na.x...),] #Get them in order of scale
nas
nas = data.frame(sapply(combine, function(x) sum(is.na(x))))
nas
View(combine)
#KAGGLE HOUSE PRICE PREDICTIONS
#Today...
# Load libraries and data -------------------------------------------------
library('caret')
library('Boruta')
library('zoo')
library('e1071')
library('rpart')
library("glmnet")
train = read.csv("train.csv", stringsAsFactors = T)
test = read.csv("test.csv", stringsAsFactors = T)
# Simple pre-processing ---------------------------------------------------
#log transform the target,
train$SalePrice = log(train$SalePrice)
test$SalePrice = 0
sp = c(train$SalePrice, test$SalePrice) #Keep the saleprice data
combine = rbind(train, test) #Combine
combine$Id = NULL
#x1 = combine$YearRemodAdd
#x2 = combine$YearBuilt
#x3 = combine$MoSold
#x4 = combine$YrSold
nums <- sapply(combine, is.numeric)
i=1
while (i<length(nums[nums=='TRUE'])) {
s = skewness(combine[,nums][i][,1], na.rm = T)
if (abs(s)>=0.75) {combine[,nums][i][,1] = log(combine[,nums][i][,1]+1)}
i=i+1
}
#combine[,nums] = log(combine[,nums]+1) #Log tranform the numeric variables
#combine$SalePrice = sp #Put the right saleprices back
#combine$YearRemodAdd = x1
#combine$YearBuilt = x2
#combine$MoSold = x3
#combine$YrSold = x4
# Tidy the data -----------------------------------------------------------------
#Majority is NAs. Get rid of them...
combine$Alley = NULL
combine$MiscFeature = NULL
combine$PoolQC = NULL
combine$Fence = NULL
combine$FireplaceQu = NULL
#Where are the NAs?
nas = data.frame(sapply(combine, function(x) sum(is.na(x))))
nas$Names = rownames(nas)
nas = data.frame(nas[nas$sapply.combine..function.x..sum.is.na.x... != 0,])
nas = nas[order(-nas$sapply.combine..function.x..sum.is.na.x...),] #Get them in order of scale
i=1
while (i<=length(nas$Names)) {
temp = nas$Names[i]
temp_data = combine[!is.na(combine[,temp]),]
if (is.factor(combine[,nas$Names[i]])) {
temp_fit = rpart(temp_data[,temp] ~ ., method = 'class', data = temp_data)
combine[,temp][is.na(combine[,temp])] <- predict(temp_fit, combine[is.na(combine[,temp]),], type = 'class')
} else {
combine[,temp][is.na(combine[,temp])] = mean(combine[,temp], na.rm = T)
}
i=i+1
}
nas = data.frame(sapply(combine, function(x) sum(is.na(x))))
nas
View(combine)
combine$New1 = combine$TotalBsmtSF * combine$BsmtFinSF1
combine$New2 = combine$GarageCars * combine$GarageArea
combine$New3 = combine$GarageCars * combine$GarageYrBlt
combine$Remod = 0
combine$Remod[combine$YearBuilt != combine$YearRemodAdd] = 1
combine$Remod = as.factor(combine$Remod)
combine$AgeSold = combine$YrSold - combine$YearBuilt
combine$DateSold = paste(as.character(combine$MoSold), as.character(combine$YrSold), sep = '-')
combine$DateSold = as.yearmon(combine$DateSold, "%m-%Y")
combine$Total_sqf = combine$X1stFlrSF + combine$X2ndFlrSF + combine$LowQualFinSF + combine$GrLivArea
combine$Total_baths = combine$BsmtFullBath + combine$BsmtHalfBath + combine$FullBath + combine$HalfBath
combine$Total_outside = combine$WoodDeckSF + combine$OpenPorchSF + combine$EnclosedPorch + combine$X3SsnPorch + combine$ScreenPorch
colnames(combine[,75])
colnames(combine)[75]
combine_p <- preProcess(combine[,-75], method = c("center", "scale"))
combine_t <- predict(combine_p, newdata = combine[,-75])
combine_t = cbind(combine_t, combine$SalePrice)
combine_t$Id = seq(1,2919,1)
combine = combine_t
colnames(combine)[84] = 'SalePrice'
train = combine[1:1460,]
test = combine[1461:2919,]
set.seed(1)
bor.results <- Boruta(train, train$SalePrice, maxRuns=20, doTrace=0)
bor.results
plot(bor.results)
att = getSelectedAttributes(bor.results, withTentative = T)
train_bor = train[att]
test_bor = test[att]
train_bor$Remod = as.factor(train_bor$Remod)
test_bor$Remod = as.factor(test_bor$Remod)
set.seed(1)
fitControl <- trainControl(method = "repeatedcv", number = 5, repeats = 5, verboseIter=FALSE,
classProbs=FALSE)
library('caretEnsemble')
model_list <- caretList(SalePrice ~. -Id,
data=train_bor,
trControl=fitControl,
tuneList = list(
glmnet=caretModelSpec(method = 'glmnet'),
gbm=caretModelSpec(method = 'gbm'),
rf=caretModelSpec(method = 'rf'),
xgbTree=caretModelSpec(method = 'xgbTree')),
metric = 'RMSE')
model_list <- caretList(SalePrice ~.,
data=train_bor,
trControl=fitControl,
tuneList = list(
glmnet=caretModelSpec(method = 'glmnet'),
gbm=caretModelSpec(method = 'gbm'),
rf=caretModelSpec(method = 'rf'),
xgbTree=caretModelSpec(method = 'xgbTree')),
metric = 'RMSE')
model_list
gbm_ensemble <- caretStack(
model_list,
method="gbm",
metric="RMSE",
trControl=trainControl(
method="boot",
number=10,
savePredictions="final"
)
)
summary(gbm_ensemble)
ens_preds <- predict(gbm_ensemble, newdata=test_bor)
ens_preds = exp(ens_preds)
sample = read.csv('sample_submission.csv')
sub = data.frame(test_bor$Id, ens_preds)
colnames(sub) = c("Id", "SalePrice")
test_bor$Id
sub = data.frame(ens_preds)
"Id",
colnames(sub) = c("SalePrice")
write.csv(sub, "sub_041116c.csv")
summary(gbm_ensemble)
getTrainPerf(model_list$xgb)
model_list$xgb
getTrainPerf(model_list$xgb)
getTrainPerf(model_list$gbm)
getTrainPerf(model_list$rf)
getTrainPerf(model_list$glmnet)
getTrainPerf(model_list$glmnet)
model_list$glmnet
set.seed(123)  # for reproducibility
model_lasso <- train(SalePrice ~.,
data = train_bor,
method="glmnet",
metric="RMSE",
maximize=FALSE,
trControl=fitControl,
tuneGrid=expand.grid(alpha=1,  # Lasso regression
lambda=c(1,0.1,0.05,0.01,seq(0.009,0.001,-0.001),
0.00075,0.0005,0.0001)))
model_lasso
getTrainPerf(model_lasso)
set.seed(1)
fitControl <- trainControl(method = "repeatedcv", number = 5, repeats = 5, verboseIter=FALSE,
classProbs=FALSE)
# set up the cross-validated hyper-parameter search
gbm_grid = expand.grid(interaction.depth = c(1, 5, 9),
n.trees = (1:30)*50,
shrinkage = 0.1,
n.minobsinnode = 10)
rf_grid = expand.grid(.mtry=c(1:15))
xgb_grid = expand.grid(nrounds = 1000,
eta = c(0.03, 0.003, 0.0003),
max_depth = c(2, 4, 6, 8, 10),
colsample_bytree = 0.4,
min_child_weight = 1,
gamma = 0.1)
glmnet = expand.grid(alpha=1,  lambda=c(1,0.1,0.05,0.01,seq(0.009,0.001,-0.001),
0.00075,0.0005,0.0001))
model_list <- caretList(SalePrice ~.,
data=train_bor,
trControl=fitControl,
tuneList = list(
glmnet=caretModelSpec(method = 'glmnet', tuneGrid=glmnet),
gbm=caretModelSpec(method = 'gbm', tuneGrid=gbm_grid),
rf=caretModelSpec(method = 'rf', tuneGrid=rf_grid),
xgbTree=caretModelSpec(method = 'xgbTree', tuneGrid=xgb_grid)),
metric = 'RMSE')
model_list
getTrainPerf(model_list$glmnet)
getTrainPerf(model_list$rf)
getTrainPerf(model_list$gbm)
getTrainPerf(model_list$xgb)
caret_list_data = save(model_list, file = 'caret_list_data.RData')
gbm_ensemble <- caretStack(
model_list,
method="nnet",
metric="RMSE",
trControl=trainControl(
method="boot",
number=10,
savePredictions="final"
)
)
summary(gbm_ensemble)
gbm_ensemble
gbm_ensemble <- caretStack(
model_list,
method="gbm",
metric="RMSE",
trControl=trainControl(
method="boot",
number=10,
savePredictions="final"
)
)
summary(gbm_ensemble)
gbm_ensemble
ens_preds <- predict(gbm_ensemble, newdata=test_bor)
ens_preds = exp(ens_preds)
sample = read.csv('sample_submission.csv')
sub = data.frame(ens_preds)
colnames(sub) = c("SalePrice")
write.csv(sub, "sub_041116d.csv")
