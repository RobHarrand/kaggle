{
    "contents" : "#KAGGLE HOUSE PRICE PREDICTIONS\n\n\n#Today...\n\n\n\n# Load libraries and data -------------------------------------------------\n\nlibrary('caret')\nlibrary('Boruta')\nlibrary('zoo')\nlibrary('e1071')\nlibrary('rpart')\nlibrary(\"glmnet\")\n\ntrain = read.csv(\"train.csv\", stringsAsFactors = T)\ntest = read.csv(\"test.csv\", stringsAsFactors = T)\n\n\n\n# Simple pre-processing ---------------------------------------------------\n\n#log transform the target,\ntrain$SalePrice = log(train$SalePrice)\n\ntest$SalePrice = 0\n\nsp = c(train$SalePrice, test$SalePrice) #Keep the saleprice data\n\ncombine = rbind(train, test) #Combine\ncombine$Id = NULL\n\n#x1 = combine$YearRemodAdd\n#x2 = combine$YearBuilt\n#x3 = combine$MoSold\n#x4 = combine$YrSold\n\nnums <- sapply(combine, is.numeric)\n\ni=1\n\nwhile (i<length(nums[nums=='TRUE'])) {\n    \n    s = skewness(combine[,nums][i][,1], na.rm = T)\n    if (abs(s)>=0.75) {combine[,nums][i][,1] = log(combine[,nums][i][,1]+1)}\n    \ni=i+1\n    \n}\n\n#combine[,nums] = log(combine[,nums]+1) #Log tranform the numeric variables\n\n#combine$SalePrice = sp #Put the right saleprices back\n#combine$YearRemodAdd = x1\n#combine$YearBuilt = x2\n#combine$MoSold = x3\n#combine$YrSold = x4\n\n\n\n# Tidy the data -----------------------------------------------------------------\n\n\n#Majority is NAs. Get rid of them...\ncombine$Alley = NULL\ncombine$MiscFeature = NULL\ncombine$PoolQC = NULL\ncombine$Fence = NULL\ncombine$FireplaceQu = NULL\n\n#Where are the NAs?\nnas = data.frame(sapply(combine, function(x) sum(is.na(x))))\nnas$Names = rownames(nas)\nnas = data.frame(nas[nas$sapply.combine..function.x..sum.is.na.x... != 0,])\nnas = nas[order(-nas$sapply.combine..function.x..sum.is.na.x...),] #Get them in order of scale\n\n#Use rpart to predict all the missing values...\n\n# i=1\n# \n# while (i<=length(nas$Names)) {\n# \n#     temp = nas$Names[i]\n#     temp_data = combine[!is.na(combine[,temp]),]\n#     \n#     if (is.factor(combine[,nas$Names[i]])) {\n#         \n#         temp_fit = rpart(temp_data[,temp] ~ ., method = 'class', data = temp_data)\n#         combine[,temp][is.na(combine[,temp])] <- predict(temp_fit, combine[is.na(combine[,temp]),], type = 'class')\n#         \n#     } else {\n#     \n#         temp_fit = rpart(temp_data[,temp] ~ ., method = 'anova', data = temp_data)\n#         combine[,temp][is.na(combine[,temp])] <- predict(temp_fit, combine[is.na(combine[,temp]),])\n#         \n#     }\n#     i=i+1\n# }\n\n#Just use means...\n\ni=1\n\nwhile (i<=length(nas$Names)) {\n    \n    temp = nas$Names[i]\n    temp_data = combine[!is.na(combine[,temp]),]\n    \n    if (is.factor(combine[,nas$Names[i]])) {\n        \n        temp_fit = rpart(temp_data[,temp] ~ ., method = 'class', data = temp_data)\n        combine[,temp][is.na(combine[,temp])] <- predict(temp_fit, combine[is.na(combine[,temp]),], type = 'class')\n        \n    } else {\n        \n        combine[,temp][is.na(combine[,temp])] = mean(combine[,temp], na.rm = T)\n    \n    }\n    i=i+1\n}\n\n#sapply(combine, function(x) sum(is.na(x)))\n\n\n#write.csv(combine, \"combined_no_na.csv\")\ncombine = read.csv(\"combined_no_na.csv\")\ncombine$X = NULL\n\n\n\n# Feature Engineering -----------------------------------------------------\n\n\n#Correlations\n\n# library('corrplot')\n# \n# n = train_bor[sapply(train_bor, class) == 'numeric']\n# n\n# \n# correlations <- cor(n, use=\"everything\")\n# corrplot(correlations, method=\"circle\", type=\"lower\",  sig.level = 0.01, insig = \"blank\")\n# \n# correlations[correlations > 0.5 & correlations < 1]\n\n\ncombine$New1 = combine$TotalBsmtSF * combine$BsmtFinSF1\ncombine$New2 = combine$GarageCars * combine$GarageArea\ncombine$New3 = combine$GarageCars * combine$GarageYrBlt\ncombine$Remod = 0\ncombine$Remod[combine$YearBuilt != combine$YearRemodAdd] = 1\ncombine$Remod = as.factor(combine$Remod)\ncombine$AgeSold = combine$YrSold - combine$YearBuilt\n\ncombine$DateSold = paste(as.character(combine$MoSold), as.character(combine$YrSold), sep = '-')\ncombine$DateSold = as.yearmon(combine$DateSold, \"%m-%Y\")\n\ncombine$Total_sqf = combine$X1stFlrSF + combine$X2ndFlrSF + combine$LowQualFinSF + combine$GrLivArea\ncombine$Total_baths = combine$BsmtFullBath + combine$BsmtHalfBath + combine$FullBath + combine$HalfBath\ncombine$Total_outside = combine$WoodDeckSF + combine$OpenPorchSF + combine$EnclosedPorch + combine$X3SsnPorch + combine$ScreenPorch\n\ncombine$X1stFlrSF = NULL\ncombine$X2ndFlrSF = NULL\ncombine$LowQualFinSF = NULL\ncombine$GrLivArea = NULL\ncombine$BsmtFullBath = NULL\ncombine$BsmtHalfBath = NULL\ncombine$FullBath = NULL\ncombine$HalfBath = NULL\ncombine$WoodDeckSF = NULL\ncombine$OpenPorchSF = NULL\ncombine$EnclosedPorch = NULL\ncombine$X3SsnPorch = NULL\ncombine$ScreenPorch = NULL\ncombine$BsmtFinSF1 = NULL\ncombine$BsmtFinSF2 = NULL\ncombine$BsmtUnfSF = NULL\n\n\n#Scale numerical features,\n\n\n\ncombine_p <- preProcess(combine[,-75], method = c(\"center\", \"scale\"))\n\ncombine_t <- predict(combine_p, newdata = combine[,-75])\ncombine_t = cbind(combine_t, combine$SalePrice)\ncombine_t$Id = seq(1,2919,1)\ncombine = combine_t\n\n#colnames(combine)[86] = 'Id'\ncolnames(combine)[84] = 'SalePrice'\n\n\n\n\n\n#write.csv(combine, \"combined_preprocessed.csv\")\ncombine = read.csv(\"combined_preprocessed.csv\")\ncombine$X.1 = NULL\n\ntrain = combine[1:1460,]\ntest = combine[1461:2919,]\n\n\n\n# Feature importance ------------------------------------------------------\n\nset.seed(1)\nbor.results <- Boruta(train, train$SalePrice, maxRuns=20, doTrace=0)\n\n#plot(bor.results)\n\natt = getSelectedAttributes(bor.results, withTentative = T)\ntrain_bor = train[att]\ntest_bor = test[att]\n\n\n#write.csv(train_bor, \"train_bor.csv\")\n#write.csv(test_bor, \"test_bor.csv\")\ntrain_bor = read.csv(\"train_bor.csv\")\ntest_bor = read.csv(\"test_bor.csv\")\n\ncolnames(train_bor)[1] = 'Id'\ncolnames(test_bor)[1] = 'Id'\n\ntrain_bor$Remod = as.factor(train_bor$Remod)\ntest_bor$Remod = as.factor(test_bor$Remod)\n\n#write.csv(train_bor$DateSold, \"train_date.csv\")\n#write.csv(test_bor$DateSold, \"test_date.csv\")\n#train_date = read.csv(\"train_date.csv\")\n#test_date = read.csv(\"test_date.csv\")\n\n#train_bor$DateSold = train_date$x #Put this back in\n#test_bor$DateSold = test_date$x #Put this back in\n\n\n\n# Fit the model -----------------------------------------------------------\n\nset.seed(1)\nfitControl <- trainControl(method = \"repeatedcv\", number = 5, repeats = 5, verboseIter=FALSE,\n                          classProbs=FALSE)\n\n# set up the cross-validated hyper-parameter search\ngbm_grid = expand.grid(interaction.depth = c(1, 5, 9), \n                       n.trees = (1:30)*50, \n                       shrinkage = 0.1,\n                       n.minobsinnode = 10)\n\nrf_grid = expand.grid(.mtry=c(1:15))\n\nxgb_grid = expand.grid(nrounds = 1000,\n                         eta = c(0.03, 0.003, 0.0003),\n                         max_depth = c(2, 4, 6, 8, 10),\n                         colsample_bytree = 0.4,\n                         min_child_weight = 1,\n                         gamma = 0.1)\n\n\nglmnet = expand.grid(alpha=1,  lambda=c(1,0.1,0.05,0.01,seq(0.009,0.001,-0.001),\n                                                   0.00075,0.0005,0.0001))\n\n\n# model = train(SalePrice ~., \n#               data = train_bor,\n#               method = 'glmnet',\n#               trControl = fitControl, \n#               #preProcess=c(\"pca\"),\n#               metric = \"RMSE\")\n\n# model = train(SalePrice ~., \n#               data = train_bor,\n#               method = 'gbm',\n#               trControl = fitControl, \n#               tuneGrid = gbm_grid,\n#               #preProcess=c(\"pca\"),\n#               metric = \"RMSE\")\n# \n# \n# model2 = train(SalePrice ~., \n#                data = train_bor,\n#                method = 'glm',\n#                trControl = fitControl, \n#                #tuneGrid = grid,\n#                #preProcess=c(\"pca\"),\n#                metric = \"RMSE\")\n# \n# \n# model3 = train(SalePrice ~., \n#                data = train_bor,\n#                method = 'rf',\n#                trControl = fitControl, \n#                #tuneGrid = grid,\n#                #preProcess=c(\"pca\"),\n#                metric = \"RMSE\")\n# \n# \n# model4 = train(SalePrice ~., \n#                data = train_bor,\n#                method = 'xgbTree',\n#                trControl = fitControl , \n#                tuneGrid = xgb_grid_1,\n#                #preProcess=c(\"pca\"),\n#                metric = \"RMSE\")\n# \n#getTrainPerf(model4)\n# getTrainPerf(model2)\n# getTrainPerf(model3)\n# getTrainPerf(model4)\n# \n# \nlibrary('caretEnsemble')\n\n#With expanded tuning...\n# model_list <- caretList(SalePrice ~. -Id, \n#                         data=train_bor,\n#                         trControl=fitControl,\n#                         tuneList = list(\n#                             gbm=caretModelSpec(method = 'gbm', tuneGrid=gbm_grid),\n#                             rf=caretModelSpec(method = 'rf', tuneGrid=rf_grid),\n#                             xgbTree=caretModelSpec(method = 'xgbTree', tuneGrid=xgb_grid)),\n#                         metric = 'RMSE')\n\n#Default tuning...\nmodel_list <- caretList(SalePrice ~., \n                        data=train_bor,\n                        trControl=fitControl,\n                        tuneList = list(\n                            glmnet=caretModelSpec(method = 'glmnet', tuneGrid=glmnet),\n                            gbm=caretModelSpec(method = 'gbm', tuneGrid=gbm_grid),\n                            rf=caretModelSpec(method = 'rf', tuneGrid=rf_grid),\n                            xgbTree=caretModelSpec(method = 'xgbTree', tuneGrid=xgb_grid)),\n                        metric = 'RMSE')\n\ncaret_list_data = save(model_list, file = 'caret_list_data.RData')\n\n\nmodel_list\n\ngetTrainPerf(model_list$glmnet)\ngetTrainPerf(model_list$rf)\ngetTrainPerf(model_list$gbm)\ngetTrainPerf(model_list$xgb)\n\n\ngbm_ensemble <- caretStack(\n    model_list,\n    method=\"gbm\",\n    metric=\"RMSE\",\n    trControl=trainControl(\n        method=\"boot\",\n        number=10,\n        savePredictions=\"final\"\n    )\n)\n\nsummary(gbm_ensemble)\n\n#greedy_ensemble <- caretEnsemble(model_list)\n#summary(greedy_ensemble)\n\nens_preds <- predict(gbm_ensemble, newdata=test_bor)\n\nens_preds = exp(ens_preds)\n\n#   \n# save(model4, file = 'xgb.RData')\n# load('xgb.RData')\n# \n#colnames(test_bor)[44] = 'FireplaceQu'\n\n\n#varImp(greedy_ensemble)\n#varImp(model)\n\n#p_gbm = predict(model_list$gbm, test)\n#p_rf = predict(model_list$rf, test)\n\n\n\n# Submission --------------------------------------------------------------\n\nsample = read.csv('sample_submission.csv')\n#K_sub = read.csv('K_test_sub1.csv')\n\n#plot(ens_preds, sample$SalePrice, xlim = c(0,7e5), ylim = c(0,300000))\n#points(p_gbm, sample$SalePrice, xlim = c(0,7e5), ylim = c(0,300000), col = 'red')\n#points(p_rf, sample$SalePrice, xlim = c(0,7e5), ylim = c(0,300000), col = 'blue')\n\n#p = mean(p_glm, p_gbm, p_rf)\n\n#points(p, sample$SalePrice, xlim = c(0,7e5), ylim = c(0,300000), col = 'green')\n\n#plot(p, K_sub$SalePrice, xlim = c(0,7e5), ylim = c(0,300000))\n\n#test_bor = cbind(test_bor, test$Id)\n#colnames(test_bor)[63] = 'Id'\n\nsub = data.frame(ens_preds)\ncolnames(sub) = c(\"SalePrice\")\n\nwrite.csv(sub, \"sub_041116d.csv\")\n",
    "created" : 1473062910344.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "7|26|17|49|\n21|24|57|20|\n61|16|127|16|\n131|22|203|26|\n207|21|236|50|\n240|16|379|36|\n383|13|404|33|\n",
    "hash" : "477592827",
    "id" : "A712DCEB",
    "lastKnownWriteTime" : 1478268794,
    "path" : "C:/Users/rob.harrand/Desktop/WORK/Kaggle/House_prices/HP.R",
    "project_path" : "HP.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "type" : "r_source"
}