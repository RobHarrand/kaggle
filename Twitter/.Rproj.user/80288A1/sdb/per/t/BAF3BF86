{
    "contents" : "library(twitteR)\nlibrary(ROAuth)\nlibrary(httr)\nlibrary(streamR)\n\n\n# STREAMING\n\n# The following four lines assign the right values to the variables that\n# are needed for the API call.\n\nrequestURL <- \"https://api.twitter.com/oauth/request_token\"\naccessURL <- \"https://api.twitter.com/oauth/access_token\"\nauthURL <- \"https://api.twitter.com/oauth/authorize\"\n\n# The string within the quotation marks has to be replaced with the actual\n# consumerKey and consumerSecret.\nconsumerKey <- \"WgI0Z0p5feozqtasJdyKKG0ow\"\nconsumerSecret <- \"8J87c6d5yxwig86yHdT8E5hX8GcBKWuLRzCpabNpAsYojXoOWE\"\n\n# The next two lines establish a connection to the Twitter API.\n# The system will print a URL which should be copied in a browser to receive a PIN number.\n# This PIN has to be entered in the R-console.\nmy_oauth <- OAuthFactory$new(consumerKey = consumerKey, \n                             consumerSecret = consumerSecret, \n                             requestURL = requestURL, \n                             accessURL = accessURL, \n                             authURL = authURL)\n\nmy_oauth$handshake(cainfo = system.file(\"CurlSSL\", \"cacert.pem\", package = \"RCurl\"))\n# Once the connection is established we can save it so that we do not have\n# repeat this process.\n\nsave(my_oauth, file = \"my_oauth.Rdata\")\n\nload(file = \"my_oauth.Rdata\")\nload(file = 'tweets.RData')\n\ni = 1\n\nwhile (i <= 280) {\n\nfilterStream(\"tw_gm.json\", timeout = 300, oauth = my_oauth, track = 'good morning', language = 'en')\ntweets_gm = parseTweets(\"tw_gm.json\")\n    \nex = grepl('RT', tweets_gm$text, ignore.case = FALSE) #Remove the RTs\ntweets_gm = tweets_gm[!ex,]\n\nex = grepl('good morning', tweets_gm$text, ignore.case = TRUE) #Remove anything without good morning in the main tweet text\ntweets_gm = tweets_gm[ex,]\n\nex = is.na(tweets_gm$place_lat) #Remove any with missing place_latitude information\ntweets_gm = tweets_gm[!ex,]\n\ntweets.all = rbind(tweets.all, tweets_gm) #Add to the collection\n\ni=i+1\n\nSys.sleep(5)\n\n}\n\n\nload(file = 'tweets_all.RData')\n\nex = duplicated(tweets.all$id_str)\ntweets.all = tweets.all[!ex,]\n\nlibrary(lubridate)\nlibrary(ggplot2)\nlibrary(dplyr)\n\ntweets.all$Date = sapply(strsplit(tweets.all$created_at, \" \"), \"[[\", 3)\ntweets.all$Date = paste(tweets.all$Date,\"-12-16\", sep = \"\")\ntweets.all$Time = sapply(strsplit(tweets.all$created_at, \" \"), \"[[\", 4)\ntweets.all$DateTime = paste(tweets.all$Date, tweets.all$Time)\ntweets.all$DateTime = as.POSIXct(tweets.all$DateTime, format = \"%d-%m-%y %H:%M:%S\")\ntweets.all$Time = as.POSIXct(tweets.all$Time, format = \"%H:%M:%S\")\n\ntweets.all.arranged = arrange(tweets.all, DateTime)\n\nplot(tweets.all.arranged$DateTime)\n\n#tweets.all$Time = as.POSIXlt(tweets.all$Time, format = \"%H:%M:%S\")\n\ntweets.all.arranged$Hour = hour(tweets.all.arranged$Time)\ntweets.all.arranged$Minute = minute(tweets.all.arranged$Time)\n\n#qplot(seq(1,length(tweets.all$text),1), tweets.all$DateTime)\n\n\n\n# i=0\n# j=0\n# k=0\n# \n# while (i<=23) {\n# \n#     while (j<=59) {\n#     \n#         tweets.all.arranged$Time_bin[tweets.all.arranged$Hour == i & tweets.all.arranged$Minute >= j & tweets.all.arranged$Minute < j+5] = k\n#         k=k+1\n#         j=j+5\n#     }\n#     i=i+1\n#     j=0\n# }\n\n\n\nl = length(tweets.all.arranged$text)\nn = floor(l / 100)\n\ntweets.all.arranged$Time_bin = 100\n\nk = seq(0,l,n)\n\ni=1\n\nwhile (i<length(k)) {\n\n    tweets.all.arranged$Time_bin[(k[i]:k[i+1])] = i\n    i=i+1\n\n    }\n\nplot(tweets.all.arranged$Time_bin)\n\n#qplot(tweets.all$lon, tweets.all$lat, col = tweets.all$Time_bin)\n\n\n#table(is.na(tweets.all$lat))\n#table(is.na(tweets.all$place_lat))\n\n\n#save(tweets.all, file = 'tweets_all.RData')\nwrite.csv(tweets.all, file = 'tweets_all.csv')\n\n# \n# \n# tweets.all$Time = sapply(strsplit(tweets.all$created_at, \" \"), \"[[\", 4)\n# tweets.all$Time = as.POSIXlt(tweets.all$Time, format = \"%H:%M:%S\")\n# tweets.all$Time = tweets.all$Time - 18000\n# \n# \n# hist(tweets.all$Time, breaks = 50)\n# \n# ex = grepl('good morning', tweets.all$text, ignore.case = TRUE)\n# tweets.good = tweets.all[ex,]\n# \n# ex = grepl('Thu', tweets.all$created_at, ignore.case = TRUE)\n# tweets.good = tweets.all[ex,]\n# \n# hist(tweets.good$Time, breaks = 50)\n\n\n\n\n#Load libraries,\nrequire(maptools)\nrequire(animation) \n\n#Get a world map,\ndata(wrld_simpl)\n\npar(mar = c(0,0,1,0),\n    pin = c(4,2),\n    pty = \"m\",\n    xaxs = \"i\",\n    xaxt = 'n',\n    xpd = FALSE,\n    yaxs = \"i\",\n    yaxt = 'n')\n\n\n#plot(tweets.all$Time_bin)\n\n\ni = 1\n\n#Loop through the rows and save the gif...\n\nsaveGIF(while (i <= length(table(tweets.all.arranged$Time_bin))) {\n    \n    plot(wrld_simpl, col='dark green', bg='white', border='black', ann=FALSE, axes = FALSE, main = \"Good morning, Twitter!\")\n    \n    points(tweets.all.arranged$place_lon[tweets.all.arranged$Time_bin == i], tweets.all.arranged$place_lat[tweets.all.arranged$Time_bin == i], pch = 16, col = 'red')\n\n    #abline(v = mean(tweets.all.arranged$place_lon[tweets.all.arranged$Time_bin == i]), col = 'red')\n    \n     #Plot some text,\n#      text(-125,110, paste(\"Time = \", mean(tweets.all.arranged$Hour[tweets.all.arranged$Time_bin == i]), \" hrs \",\n#                           floor(mean(tweets.all.arranged$Minute[tweets.all.arranged$Time_bin == i])), \" mins\", sep=\"\"),\n#                           col = \"black\", cex = 0.9, font = 2)\n    \n    temp = tweets.all.arranged$DateTime[tweets.all.arranged$Time_bin == i][1]    \n    \n    text(-40,110, paste(\"Date/Time = \", temp, \" GMT\"), col = \"black\", cex = 1.2, font = 2)\n    \n#     text(125,110, \"Colour = Day's weather\", col = \"black\", cex = 0.9, font = 2)\n#     \n#     points(85, 100, pch = 21, cex = 2, col = \"black\", bg = \"grey\")\n#     text(100, 101, \" - cloud \", col = \"black\", cex = 0.8, font = 2)\n#     \n#     points(115, 100, pch = 21, cex = 2, col = \"black\", bg = \"blue\")\n#     text(129, 101, \" - rain \", col = \"black\", cex = 0.8, font = 2)\n#     \n#     points(85, 92, pch = 21, cex = 2, col = \"black\", bg = \"light blue\")\n#     text(98, 93, \" - fine \", col = \"black\", cex = 0.8, font = 2)\n#     \n#     points(115, 92, pch = 21, cex = 2, col = \"black\")\n#     text(142, 93, \" - not recorded \", col = \"black\", cex = 0.8, font = 2)\n#     \n#     #text(-110,103, \"Ship's log: \", col = \"black\", cex = 1, font = 2)\n#     text(0, 110, paste(\"Date: \", Endeavour$Day[i],\"/\",Endeavour$Month[i],\"/\",Endeavour$Year[i]), col = \"black\", cex = 1, font = 2)\n#     #text(0, 100, Endeavour$Clearness[i], col = \"red\", cex = 1, font = 2)\n#     #text(0, 90, Endeavour$AllWindForces[i], col = \"red\", cex = 1, font = 2)\n#     #text(0, 90, Endeavour$PrecipitationDescriptor[i], col = \"red\", cex = 1, font = 2)\n#     \n#     #Wait a while between plots,\n#     ani.pause()\n#     \n#     #Wipe the text,\n#     #rect(-160,85,160,119, col = \"light blue\", border = NA)\n    \n    i = i+1\n    \n}, movie.name = \"goodmorning.gif\", img.name = \"Rplot\", interval = 0.1, convert = \"convert\", ani.width = 800, \nani.height = 800)\n\n\n\nqplot(tweets.all.arranged$place_lon, tweets.all.arranged$place_lat, col = as.factor(tweets.all.arranged$Time_bin))\n\n\n\n\nmap <- NULL\nmapWorld <- borders(\"world\", colour=\"black\", fill=\"gray\")\nmap <- ggplot() +   mapWorld\n\n#Now Layer the cities on top\nmap <- map + geom_point(aes(x=tweets.all.arranged$place_lon, y=tweets.all.arranged$place_lat, \n                         color=as.factor(tweets.all.arranged$Time_bin)) , size=3) + theme(legend.position=\"none\")\nmap\n\n\nplot(wrld_simpl, col='dark green', bg='white', border='black', ann=FALSE, axes = FALSE, main = \"Good morning, Twitter!\")\n\npoints(tweets.all.arranged$place_lon, tweets.all.arranged$place_lat, pch = 16, col = as.factor(tweets.all.arranged$Time_bin))\n\n\n\n\nlibrary(ggplot2)\nlibrary(grid)\nfilterStream(\"tweetsUS.json\", locations = c(-125, 25, -66, 50), timeout = 300, \n             oauth = my_oauth)\ntweets.df <- parseTweets(\"tweetsUS.json\", verbose = FALSE)\nmap.data <- map_data(\"state\")\npoints <- data.frame(x = as.numeric(tweets.df$lon), y = as.numeric(tweets.df$lat))\npoints <- points[points$y > 25, ]\nggplot(map.data) + geom_map(aes(map_id = region), map = map.data, fill = \"white\", \n                            color = \"grey20\", size = 0.25) + expand_limits(x = map.data$long, y = map.data$lat) + \n    theme(axis.line = element_blank(), axis.text = element_blank(), axis.ticks = element_blank(), \n          axis.title = element_blank(), panel.background = element_blank(), panel.border = element_blank(), \n          panel.grid.major = element_blank(), plot.background = element_blank(), \n          plot.margin = unit(0 * c(-1.5, -1.5, -1.5, -1.5), \"lines\")) + geom_point(data = points, \n                                                                                   aes(x = x, y = y), size = 1, alpha = 1/5, color = \"darkblue\")\n\n\n\ntable(tweets.df$country)\n\n\n\n\n#SEARCH\n\n\n# Set API Keys\napi_key <- \"WgI0Z0p5feozqtasJdyKKG0ow\"\napi_secret <- \"8J87c6d5yxwig86yHdT8E5hX8GcBKWuLRzCpabNpAsYojXoOWE\"\naccess_token <- \"23829577-ma8Jk6S5GogQCvYOiQppdIYNSHdMKknakHh22JY1c\"\naccess_token_secret <- \"hhi7um7oev6QSKRxGmzl2TjKca8zYrfGH67YiBEy4rOEr\"\nmy_oauth = setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)\n\n\n\n# Grab latest tweets\ntweets_harris <- userTimeline('SamHarrisOrg', n = 100, includeRts = F)\ntweets_greenwald <- userTimeline('@ggreenwald', n = 1000, includeRts = T)\ntweets_greenwald = twListToDF(tweets_greenwald)\n\ntweets_article <- searchTwitter('A liberal writes in @Guardian how he was radicalized by @SamHarrisOrg', n=1000)\ntweets_article = twListToDF(tweets_article)\n\n?searchTwitter\n\nggplot(tweets_article, aes(x=created)) +\n    geom_histogram() +\n    theme_set(theme_bw(base_size = 18)) +\n    xlab(\"Date/Time created\") + \n    ggtitle(\"Histogram of Tweets for the 'A liberal writes...' article\")\n\n\n\n#tweets_harris = tweets_harris[tweets_harris$created > '2016-10-19 00:00:00',]\n\n\ntweets_SamHarrisOrg <- searchTwitter('from:SamHarrisOrg', n=100)\ntweets_SamHarrisOrg = twListToDF(tweets_SamHarrisOrg)\n\ntweets_greenwald = tweets_SamHarrisOrg[tweets_SamHarrisOrg$screenName == 'ggreenwald',]\n\n\ntweets_SamHarrisOrg_all <- searchTwitter('SamHarrisOrg', n=3000)\ntweets_SamHarrisOrg_all = twListToDF(tweets_SamHarrisOrg_all)\ntweets_greenwald_about_harris = tweets_SamHarrisOrg_all[tweets_SamHarrisOrg_all$screenName == 'ggreenwald',]\n\nrange(tweets_harris$created)\nrange(tweets_greenwald$created)\n\ntweets_harris = twListToDF(tweets_harris)\n\n\n# Loop over tweets and extract text\n#library(plyr)\n\n#feed_harris = laply(tweets_harris, function(t) t$getText())\n#feed_greenwald = laply(tweets_greenwald, function(t) t$getText())\n\nharris_mentions_greenwald = length(grep('@ggreenwald', tweets_harris$text))\ngreenwald_mentions_harris = length(grep('@SamHarrisOrg', tweets_greenwald$text))\n\nharris_mentions_islam = length(grep('islam', tweets_harris$text))\n\nplot(tweets_harris$created[grep('@ggreenwald', tweets_harris$text)], rownames(tweets_harris)[grep('@ggreenwald', tweets_harris$text)])\nplot(tweets_greenwald$created[grep('@SamHarrisOrg', tweets_greenwald$text)], rownames(tweets_greenwald)[grep('@SamHarrisOrg', tweets_greenwald$text)])\n\nplot(tweets_harris$created[grep('islam', tweets_harris$text)], rownames(tweets_harris)[grep('islam', tweets_harris$text)])\n\nplot(tweets_greenwald_all$created, rownames(tweets_greenwald_all), type = 'l')\nlines(tweets_SamHarrisOrg$created, rownames(tweets_SamHarrisOrg), col = 'red')\n\n\n\n\n\n\n\ndoInstall <- TRUE  # Change to FALSE if you don't want packages installed.\ntoInstall <- c(\"ROAuth\", \"igraph\", \"ggplot2\", \"wordcloud\", \"devtools\", \"tm\",\n               \"R2WinBUGS\", \"rmongodb\", \"scales\")\nif(doInstall){\n    install.packages(toInstall, repos = \"http://cran.r-project.org\")\n    library(devtools)\n    # R packages to get twitter and Facebook data\n    install_github(\"streamR\", \"pablobarbera\", subdir=\"streamR\")\n    install_github(\"Rfacebook\", \"pablobarbera\", subdir=\"Rfacebook\")\n    # smapp R package\n    install_github(\"smappR\", \"SMAPPNYU\")\n}",
    "created" : 1481299289890.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4113395631",
    "id" : "BAF3BF86",
    "lastKnownWriteTime" : 1481301598,
    "path" : "C:/R/twitter.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "type" : "r_source"
}